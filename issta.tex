\section{Challenges: Testing Internal and Network Nondeterminism}
\label{sec:challenge}
To illustrate the challenges in testing networked applications, we discuss two
features of \http---conditional requests~\cite{rfc7232}
and message forwarding~\cite{rfc7231}---showcasing internal nondeterminism
and network nondeterminism, respectively.
%% \hzh{we should make sure we always use either internal/external or
%% internal/network. in particular, the 3rd contribution uses internal/external,
%% while everywhere else seems to use internal/network.}

\paragraph*{Internal Nondeterminsm}
\http requests can be conditional: if the client has a local copy of some
resource and the copy on the server has not changed, then the server needn't
resend the resource.  To
achieve this, an \http server may generate a short string, called an ``entity tag'' (ETag), identifying the
content of some resource, and send it to
the client: %% \bcp{Make the font a bit smaller}
\begin{lstlisting}[style=customc]
/* Client: */
GET /target HTTP/1.1

/* Server: */
HTTP/1.1 200 OK
ETag: "tag-foo"
... content of /target ...
\end{lstlisting}
The next time the client requests the same resource, it can include the ETag in
the GET request, informing the server not to send the content if its ETag
still matches:

\begin{lstlisting}[style=customc]
/* Client: */
GET /target HTTP/1.1
If-None-Match: "tag-foo"

/* Server: */
HTTP/1.1 304 Not Modified
\end{lstlisting}
% The server compares the request's ETag with that stored for the target
% resource.
% If matched, the server responds with code 304 and the client knows the
% target's
% content has not changed from the previously sent content.
If the tag does not
match, the server responds with code 200 and the updated content as usual.
%
Similarly, if a client wants to modify the server's resource atomically by
compare-and-swap, it can include the ETag in the PUT request as \inlinec{If-Match} precondition, which
instructs the server to only update the content if its current ETag matches.
% \begin{lstlisting}[style=customc]
% /* Client: */
% PUT /target HTTP/1.1
% If-Match: "tag-outdated"
%
% /* Server: */
% HTTP/1.1 412 Precondition Failed
% \end{lstlisting}
% The server compares the request's ETag with the target's.  If they don't match
% (indicating the client has an outdated version of the target resource), the
% server does not process the modification, and responds with code 412.  Only if
% the client provides a matching ETag does the server update the target's content
% per requested.  A pseudocode for this compare-and-swap logic is shown in
% \autoref{fig:if-match-model}.

\ly{This is a good example, but how general is the
  problem, since one might question the popularity of ETags? On the other hand,
  if your testing framework targets application layer protocols rather than just
  HTTP, maybe there are more similar examples? For example, file/mail servers or
  databases might also require some synchronization mechanisms similar to
  compare-and-swap? And there might be other examples that's not
  compare-and-swap?}\bcp{Agree that this is important to discuss.}
  \lys{Mentioned at the end of this section.}

Thus, whether a server's response should be judged {\em valid} or not
depends on the ETag it generated
when creating the resource.  If the tester doesn't know the server's internal
state ({\it e.g.}, before receiving any 200 response including the ETag), and
cannot enumerate all of them (as ETags can be arbitrary strings), then it needs
to maintain a space of all possible values, narrowing the space upon further
interactions with the server.
% ~\ly{If I understand it correctly, the
%   non-determinism mostly comes from the fact that the algorithm to generate
%   ETags is unknown and depends on a lot of server's internal states---the fact
%   that the server supports ``compare and swap'' seems less relevant? If so, I
%   think this subsection should focus more on where the non-determinism comes
%   from, and why this makes it hard for testers, rather than demonstrating how
%   HTTP/1.1 implements ``compare and swap''.}\bcp{I agree---the whole
%   compare-and-swap discussion could be reduced to a sentence.  I'll make
%   this fix.}

It is possible, but tricky, to write an ad hoc tester for \http by
manually ``dualizing'' the behaviors described by the informal specification
documents (RFCs).
The protocol document describes {\em how} a valid server should handle
requests, while the
tester needs to determine {\em what} responses received
from the server are valid.  For example, ``If the server has revealed some
resource's ETag as \inlinec{"foo"}, then it must not reject requests targetting
this resource conditioned over \inlinec{If-Match: "foo"}, until the resource has
been modified''; and ``Had the server previously rejected an \inlinec{If-Match}
request, it must reject the same request until its target has been
modified.'' \autoref{fig:etag-tester} shows a hand-written tester for
checking this bit of ETag functionality; we hope the reader will agree that
this testing logic is not straightforward to derive from the informal
``server's eye'' specifications.

\paragraph*{Network Nondeterminism}
%% \lys{Network nondeterminism seems more important as a contribution, but internal
%%   nondeterminism were discussed much more.}\sz{Maybe drop the subsection and
%%   call out ``internal'' vs. ``network'' nondeterminism via paragraphs
%%   instead?This discussion is still focused on HTTP/1.1, so they belong
%%   together?}
%% \bcp{Changed to paragraph.}

When testing an \http server over the network, although TCP preserves message
ordering within each connection, it does not guarantee any order between
different connections.  Consider a proxy model in \autoref{fig:proxy-model}: it
specifies {how} a server should forward messages. \bcp{I don't
  understand why we are talking about proxies here: a simple ``server +
  several clients'' situation is enough to create network nondeterminism.  (I
would expect that proxying might create {\em additional} possibilities for
nondeterminism, of course.)  \lys{We need to talk about proxy somewhere, and I
  didn't find a good place elsewhere.}}  \bcp{Moreover, the more I look at
  figures 2--5
the more confusing I find them.  Only figure 5 mentions connections, but ---
for example, in figure 3, if
we assume just a single connection between the observer and the proxy and a
single connection from the proxy back to the observer, then the reordering
shown in the figure is NOT valid.  \lys{Updated figure.  No proxy uses the same
  connection for multiple requests.  The proxy never knows if there's a next
  request that can use the same connection.}}
%% \bcp{Confusing: ``Servers'' do not normally forward messages---they just
%%   handle them.  \lys{I chose proxy rather than other parts of HTTP: We need
%%   to introduce proxy somewhere, and discuss network nondeterminism somewhere,
%%   so better both in here.}}
When the forwarded messages are scrambled as in \autoref{fig:proxy-valid-trace},
the tester should be {\em loose} enough to accept the server, because a valid
server may exhibit such reordering due to network delays.  The tester should
also be {\em strict} enough to reject a server that behaves as
\autoref{fig:proxy-invalid-trace}, because no network delay can let the proxy
forward a message before the observer sends it.

\iffalse
Similar reorderings can arise from the server's runtime environment: To
handle multiple clients, it is natural
to write a server that runs multiple threads concurrently, and the operating
might schedule these threads nondeterministically.  Moreover, the OS itself
might reorder messages sent and received on different TCP channels.
When testing the server over
the network, such nondeterminism outside the code of the server program but
still within the machine on which the server is executing is indistinguishable
from nondeterminism
caused by network delays, and is thus covered by the concept ``network
nondeterminism.''
\fi

The kinds of nondeterminism exemplified here can be found in many other
scenarios: (i) Servers may use some (unknown) algorithm to generate internal
state for nonces, sequence numbers, caching metadata, {\it etc}, featuring
internal nondeterminism.  (ii) When the server runs multiple threads
concurrently ({\it e.g.} to serve multiple clients), the operating system might
schedule these threads nondeterministically.  When testing the server over the
network, such ``nondeterminism outside the code of the server program but still
within the machine on which the server is executing'' is indistinguishable from
nondeterminism caused by network delays, and thus can be covered by the concept
``network nondeterminism.''

% Upon interacting with the server, our tester needs to reason about possible network
% delays, and find a corresponding server-side behavior that matches the
% interaction.

\section{Specification Language}
\label{sec:spec-language}
A specification in our framework consists of two parts: a server model
specifying
server-side behavior,\bcp{there was a discussion of this somewhere else:
  isn't our ``application model'' here just specifying HTTP and WebDAV? And
  so isn't it also generic?  \lys{Not generic over all L7 protocols.}}
and a network model describing network
delays.  By
composing these two models, we get a tester-side specification of valid
observations over the network.

Formally, our specifications are written as {\em interaction trees}, a generic
data structure for representing interactive programs in Coq.  This language
allows us to write rigorous mathematical specifications, and transform the
specification into tester conveniently.  In this
paper, we present models as pseudocode for readability.  Technical details
about interaction trees can be found in \cite{itree}.

\autoref{sec:app-model} shows how to handle network nondeterminism.
\autoref{sec:symbolic-model} then expands the model to address internal
nondeterminism.

\subsection{Server and Network Models}
\label{sec:app-model}

The {\em server model} specifies how the server code
interacts with the network interface.  For example, an extremely simplistic model of
an HTTP proxy\bcp{again, it feels like proxies are coming out of nowhere
  \lys{I'll try to make proxy more like a part of HTTP than an extension.}}
(shown in \autoref{fig:proxy-model}) is written as:

\begin{lstlisting}[style=customcoq]
let proxy() =
    msg := recv();
    send(msg);
    proxy()
\end{lstlisting}

An implementation is said to be {\em valid} if it is indistinguishable from
the model when viewed from across the network.  Consider
the following proxy implementation that reorders messages:
%% \bcp{We need a way of better distinguishing models from implementations,
%%   e.g. a naming convention that will make clear which is which.  ``proxy''
%%   and ``proxy\_reorder'' sound like they could be either.}
\bcp{Why are we suddenly switching to C syntax??  \lys{To distinguish
    implementation from specification.}}

\begin{lstlisting}[style=customc]
  void proxy_implementation() {
    while (true) {
      recv(&msg1); recv(&msg2);
      send(msg2);  send(msg1);
    }
  }
\end{lstlisting}
This reordered implementation is valid, because the model itself may
exhibit the same behavior when observed over the network, as shown in
\autoref{fig:proxy-valid-trace}.  This ``implementation's behavior is
explainable by the model, considering network delays''
relation is called {\em network refinement} by
\textcite{cpp19}.
%% \bcp{This doesn't sound right: refinement should be an
%%   asymmetric relation, but indistinguishability shoud be symmetric.}

To specify network refinement in a testable way, we introduce
the {\em network model}, a conceptual implementation of the transport-layer
environment between the server and the tester.  It models the network as a
nondeterministic machine that absorbs packets and,  after some time, emits
them again.  \autoref{fig:tcp-model} shows the network model for concurrent TCP
connections: The network
either
receives a packet from some node, or sends the first packet en route of some
connection.  This model preserves the message order within each connection,
but it exhibits all possible reorderings among different connections.

The network model does not distinguish between server and tester.  When one end
\ilc{send}s some message, the network \ilc{recv}s the message and \ilc{send}s it
after some cycles of delay; it is then observed by the other end via some
\ilc{recv} call.

In \autoref{sec:net-compose}, we compose the server and network models to yield an
observer-side specification for testing purposes.

\subsection{Symbolic Representation of Nondeterministic Data}
\label{sec:symbolic-model}

To incorporate symbolic evaluation in our testing framework, our specification
needs to represent internally generated data as symbols.  Consider HTTP
PUT requests with \inlinec{If-Match} preconditions: Upon success, the server
generates a new ETag for the updated content, and the tester does not know the
ETag's value immediately.  Our symbolic model in \autoref{fig:if-match-model}
represents the server's generated ETags as fresh variables.  The server's future
behavior might depend on whether a request's ETag matches the generated
(symbolic) ETag.  Such matching produces a symbolic boolean expression, which
cannot be evaluated into a boolean value without enough constraints on its
variables.  Our model introduces \ilc{IF} operator to condition branches over
a symbolic boolean expression.  Which branch the server actually took is decided
by the derived tester in \autoref{sec:derivation}.

In \autoref{sec:derive-internal}, we implement the symbolic evaluation process
that checks servers' observable behavior against this symbolic model.

\section{Derivation: from Server Specification to Testing Program}
From the specified the application and network models,
%% \sz{Remind the reader what the L7 and L4 models do, per the comment made
%% later. Also, will the L4 level be shared across many L7 models?},
our framework automatically derives a tester program that
interacts with the server and determines its validity.  The derivation framework
is shown in outline in \autoref{fig:framework}.  Each box is an interaction tree
program, and the arrows are
%% \ly{Maybe this is clear to experts, but I'm not clear what's the
%%   difference between a model program and a reference implementation. Or are they
%%   the same thing?}\bcp{I also don't understand ``model program''}
``interpretors'' that transform one interaction tree into another.
\autoref{sec:interpret} explains the concept of interpretation, and the rest of
this section describes how to interpret the specification into a tester program.
%% \bcp{``instantiating the model's events with specific rules'' doesn't say
%% much to me; hopefully this becomes clearer below, but we should avoid
%% confusing readers here too.}

\subsection{Interpreting Interaction Trees}
\label{sec:interpret}

\subsection{From Server Specification to Tester Program}
\label{sec:derive-internal}

For simplicity, we first explain how to handle servers' internal nondeterminism
with symbolic evaluation.  This subsection covers a subgraph of
\autoref{fig:framework}, starting with dualizing the symbolic model.
Here we use the server model itself as the symbolic model, assuming no
reorderings by network delays.  We will compose the server model with the
network model in \autoref{sec:net-compose}, addressing network nondeterminism.

\paragraph*{Test Case Generation}
% \label{sec:test-case}

\begin{figure}
  \begin{lstlisting}[style=customcoq]
let http_server (http_st) =
  request := recv_HTTP(http_st);
  (response, st') := process(request, http_st);
  http_server (st')
...
let observer (server) =
  match server with
  | req := recv_HTTP(http_st); s'(req) =>
    r1  := gen_Observer(http_st);
    send(r1); observe (s'(r1))
...
let unifier (observer, vars, conn) =
  match observer with
  | req := gen_Observer(http_st); o'(req) =>
    r1  := gen_Unifier(http_st, vars, conn);
    unifier (o'(r1), vars, conn)
...
  \end{lstlisting}
  \caption{Embedding programs' internal state into the events.  By
    expanding the events' parameters, we enrich the test case generator's
    knowledge along the interpretations.}
  \label{fig:test-case}
\end{figure}

%% \sz{I didn't get the following explanation at all.  Have we introduce the
%% term ``phase'' anywhere yet? What are the phases?}
Counterexamples are sparsely distributed, especially when the bugs are related
to server's internally generated data like ETags, which can hardly be matched by
a random test case generator.  After observing the \inlinec{ETag} field of some
response, the generator can send more requests with the same ETag value, rather
than choosing an unknown value arbitrarily.

As shown in \autoref{fig:test-case}, our derivation framework allows passing the
programs' internal state as the events' parameters, so the test case
generator can utilize the states in all intermediate interpretation phases, and
apply heuristics to emphasise certain bug patterns.

%% \sz{I think this example should go first before trying to explain the idea
%% more generally. I think what we're trying to get at is that the tester can
%% use the model server's internal state to generate better tests, right?}

Notice that the state-passing strategy only allows tuning {\em what} messages to
send.  To reveal bugs more efficiently in an interactive scenario, we need to
tune {\em when} the interactions are made, which is further discussed in
\autoref{sec:eval-performance}.  Generating test cases in certain orders is to
be explored in future work.

\pagebreak
\subsection{Network Composition}

\begin{figure}
  \begin{lstlisting}[style=customcoq,numbers=left,stepnumber=1,escapechar=\%]
let compose (net, bi, bo, srv) =
  let step_net =
    match net with
    | send(pkt); n' =>
      if pkt.to_server
      then compose (n', bi++[pkt], bo, srv)%\label{line:app-incoming}%
      else send(pkt);   (* to client *)%\label{line:net-emit}%
           compose (n', bi, bo, srv)
      end
    | pkt := recv(); n'(pkt) => %\label{line:net-recv}%
      match bo with
      | p0::b' => compose (n'(p0), bi, b', srv) %\label{line:net-absorb}%
      | []     => p1 := recv(); %\label{line:client-send}%
                 compose (n'(p1), bi, bo, srv)
      end
    | r  := _(); n'(r) =>
      r1 := _(); compose (n'(r1), bi, bo, srv)
    end in
  match srv with
  | send(pkt); s' =>
    compose (net, bi, bo++[pkt], s') %\label{line:app-send}%
  | pkt := recv(); s'(pkt) =>
    match bi with
    | p0::b' => compose (net, b', bo, s'(p0)) %\label{line:app-consume}%
    | []     => step_net %\label{line:step-net}%
    end
  | r  := _(); s'(r) =>
    r1 := _(); compose (net, bi, bo, s'(r1))
  end in
compose (tcp, [], [], http)
  \end{lstlisting}
  \caption{Composing \ilc{http} server model with \ilc{tcp} network model by interpreting
    their events and passing messages from one model to another.  The composing
    function takes four parameters: server and network models as \ilc{srv} and \ilc{net},
    and the message buffers between them.  When \ilc{srv} wants to \ilc{send} a
    packet in \autoref{line:app-send}, the packet is appended to the outgoing
    buffer \ilc{bo} until absorbed by \ilc{net} in \autoref{line:net-absorb},
    and eventually emitted to the client in \autoref{line:net-emit}.
    Conversely, packets sent by clients are absorbed by \ilc{net} in
    \autoref{line:client-send}, emitted to the application's incoming buffer
    \ilc{bi} in \autoref{line:app-incoming}, until \ilc{srv} consumes it in
    \autoref{line:app-consume}.
    %% \bcp{This figure is {\em very} hard to read and understand.  First, the
    %% ML notation will be unfamiliar for most ISSTA readers.  And second, I
    %% can't understand it myself.  For example, what are ``others'' and
    %% ``others()'' and what's the difference between them?  What is
    %% pkt.destination?  What are the initial values tcp\_L4 and http\_L7?  How
    %% does the result of zip actually get executed?}
  }
  \label{fig:net-compose}
\end{figure}
%% \sz{We should give this intuition about what L7 does way back at the start of
%% Section 4 where we describe Figure 7 (and give a similar description of L4).
%% We should probably remind the reader again here.}
We have shown how to derive a tester from the server model itself.
The server model describes how a reference server processes messages.  For
protocols like \http where servers are expected to handle one request at a time,
a reasonable server model should be ``linear'' that serves one client after another.
As a result, the derived tester only simulates a single client, and does not
attempt to observe the server's behavior via multiple simultaneous connections.

The network model describes how messages sent by one end of the network are
eventually received by the other end.  When interacting with multiple clients, a
valid server's observable behavior should be explainable by ``server delayed by the
network'', as discussed in \autoref{sec:app-model}.  To model this set of
observations, we compose the server and network models by attaching the server
model as one end on the network model.

As shown in \autoref{fig:net-compose}, we \ilc{compose} the events of server and
network
%% \sz{I wonder if renaming the term ``zip'' to ``compose'' might be more
%% consistent and evocative of what we're trying to explain?}
models.  Messages sent by the server are received by the network and sent to clients after some
delay, and vice versa.  Such composition produces a model that branches
nondeterministically, and includes all possible interactions of a valid HTTP
server that appear on the client side.

The composed model does not introduce new events that were not included in the server model:
The network model in \autoref{fig:tcp-model} does perform nondeterministc \ilc{or}
branches, but \ilc{or(x,y)} is a syntactic sugar for \ilc{b := fresh(); IF(b,x,y)}.
Therefore, using the same derivation algorithm from the server model to
single-connection tester program, we can derive the composed server+network model into a
multi-connection tester.

Notice that the server and network events are scheduled at different priorities: The
composition algorithm steps into the network model lazily, not until the
server is blocked in \autoref{line:step-net}.  When the network wants to
\ilc{recv} some packet in \autoref{line:net-recv}, it prioritizes packets sent
by the server, and only receives from the clients if the server's
outgoing buffer has been exhausted.  Such design is to enforce the tester to
terminate upon observing invalid behavior: When the server's behavior violates
the model, the tester should check all possible branches and determine that none
of them can lead to such behavior.  If the model steps further into the network, it would
include infinitely many \ilc{absorb} branches in \autoref{fig:tcp-model}, so the
derived tester will never exhaust ``all'' branches and reject the server.
Scheduling network events only when the server model is blocked produces sufficient nondeterminism to
accept valid servers.
%\lys{Proof?}
%% \bcp{Very confusing.}
