@inproceedings{Quviq2006,
author = {Arts, Thomas and Hughes, John and Johansson, Joakim and Wiger, Ulf},
title = {Testing Telecoms Software with Quviq QuickCheck},
year = {2006},
isbn = {1595934901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1159789.1159792},
doi = {10.1145/1159789.1159792},
abstract = {We present a case study in which a novel testing tool, Quviq QuickCheck, is used to
test an industrial implementation of the Megaco protocol. We considered positive and
negative testing and we used our developed specification to test an old version in
order to estimate how useful QuickCheck could potentially be when used early in development.The
results of the case study indicate that, by using Quviq QuickCheck, we would have
been able to detect faults early in the development.We detected faults that had not
been detected by other testing techniques. We found unclarities in the specifications
and potential faults when the software is used in a different setting. The results
are considered promising enough to Ericsson that they are investing in an even larger
case study, this time from the beginning of the development of a new product.},
booktitle = {Proceedings of the 2006 ACM SIGPLAN  Workshop on Erlang},
pages = {2–10},
numpages = {9},
keywords = {property based testing, test automation},
location = {Portland, Oregon, USA},
series = {ERLANG '06}
}

@inproceedings{Hughes2007,
  abstract  = {One of the nice things about purely functional languages is that functions often satisfy simple properties, and enjoy simple algebraic relationships. Indeed, if the functions of an API satisfy elegant laws, that in itself is a sign of a good design---the laws not only indicate conceptual simplicity, but are useful in practice for simplifying programs that use the API, by equational reasoning or otherwise.},
  address   = {Berlin, Heidelberg},
  author    = {Hughes, John},
  booktitle = {Practical Aspects of Declarative Languages},
  editor    = {Hanus, Michael},
  isbn      = {978-3-540-69611-7},
  pages     = {1--32},
  publisher = {Springer Berlin Heidelberg},
  title     = {QuickCheck Testing for Fun and Profit},
  year      = {2007},
}

@inbook{Hughes2016,
  abstract  = {This is not a typical scientific paper. It does not present a new method, with careful experiments to evaluate it, and detailed references to related work. Rather, it recounts some of my experiences over the last 15 years, working with QuickCheck, and its purpose is as much to entertain as to inform.},
  address   = {Cham},
  author    = {Hughes, John},
  booktitle = {A List of Successes That Can Change the World: Essays Dedicated to Philip Wadler on the Occasion of His 60th Birthday},
  doi       = {10.1007/978-3-319-30936-1_9},
  editor    = {Lindley, Sam
and McBride, Conor
and Trinder, Phil
and Sannella, Don},
  isbn      = {978-3-319-30936-1},
  pages     = {169--186},
  publisher = {Springer International Publishing},
  title     = {Experiences with QuickCheck: Testing the Hard Stuff and Staying Sane},
  url       = {https://doi.org/10.1007/978-3-319-30936-1_9},
  year      = {2016},
}

@inproceedings{issta21,
      title={Model-Based Testing of Networked Applications},
      author={Yishuai Li and Benjamin C. Pierce and Steve Zdancewic},
      year={2021},
      booktitle={ACM SIGSOFT International Symposium on Software Testing and Analysis}
}


@book{quickchick,
  title = {QuickChick: Property-Based Testing in Coq},
  author = {Leonidas Lampropoulos and
            Benjamin C. Pierce},
  year = {2018},
  series = {Software Foundations series, volume 4},
  publisher = {Electronic textbook},
  url = {https://softwarefoundations.cis.upenn.edu/qc-current/index.html}
}

@inproceedings{cpp19,
 author = {Koh, Nicolas and Li, Yao and Li, Yishuai and Xia, Li-yao and Beringer, Lennart and Honor{\'e}, Wolf and Mansky, William and Pierce, Benjamin C. and Zdancewic, Steve},
 title = {From C to Interaction Trees: Specifying, Verifying, and Testing a Networked Server},
 booktitle = {Proceedings of the 8th ACM SIGPLAN International Conference on Certified Programs and Proofs},
 series = {CPP 2019},
 year = {2019},
 isbn = {978-1-4503-6222-1},
 location = {Cascais, Portugal},
 pages = {234--248},
 numpages = {15},
 url = {http://doi.acm.org/10.1145/3293880.3294106},
 doi = {10.1145/3293880.3294106},
 acmid = {3294106},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {QuickChick, TCP, VST, formal verification, interaction trees, network refinement, testing},
}

@article{itree,
 author = {Xia, Li-yao and Zakowski, Yannick and He, Paul and Hur, Chung-Kil and Malecha, Gregory and Pierce, Benjamin C. and Zdancewic, Steve},
 title = {Interaction Trees: Representing Recursive and Impure Programs in Coq},
 journal = {Proc. ACM Program. Lang.},
 issue_date = {January 2020},
 volume = {4},
 number = {POPL},
 month = dec,
 year = {2019},
 issn = {2475-1421},
 pages = {51:1--51:32},
 articleno = {51},
 numpages = {32},
 url = {http://doi.acm.org/10.1145/3371119},
 doi = {10.1145/3371119},
 acmid = {3371119},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Coq, coinduction, compiler correctness, monads},
}

@misc{rfc793,
	series =	{Request for Comments},
	number =	793,
	howpublished =	{RFC 793},
	publisher =	{RFC Editor},
	doi =		{10.17487/RFC0793},
	url =		{https://www.rfc-editor.org/info/rfc793},
        author =	{Postel, Jon},
	title =		{{Transmission Control Protocol}},
	pagetotal =	91,
	year =		1981,
	month =		sep,
}

@misc{rfc2616,
	series =	{Request for Comments},
	number =	2616,
	howpublished =	{RFC 2616},
	publisher =	{RFC Editor},
	doi =		{10.17487/RFC2616},
	url =		{https://www.rfc-editor.org/info/rfc2616},
        author =	{Fielding, Roy T. and Gettys, Jim and Mogul, Jeffrey C. and Frystyk, Henrik and Masinter, Larry and Leach,  Paul and Berners-Lee, Tim},
	title =		{{Hypertext Transfer Protocol -- HTTP/1.1}},
	pagetotal =	176,
	year =		1999,
	month =		jun,
	abstract =	{HTTP has been in use by the World-Wide Web global information initiative since 1990. This specification defines the protocol referred to as "HTTP/1.1", and is an update to RFC 2068. {[}STANDARDS-TRACK{]}},
}

@misc{rfc4918,
	series =	{Request for Comments},
	number =	4918,
	howpublished =	{RFC 4918},
	publisher =	{RFC Editor},
	doi =		{10.17487/RFC4918},
	url =		{https://www.rfc-editor.org/info/rfc4918},
        author =	{Lisa M. Dusseault},
	title =		{{HTTP Extensions for Web Distributed Authoring and Versioning (WebDAV)}},
	pagetotal =	127,
	year =		2007,
	month =		jun,
	abstract =	{Web Distributed Authoring and Versioning (WebDAV) consists of a set of methods, headers, and content-types ancillary to HTTP/1.1 for the management of resource properties, creation and management of resource collections, URL namespace manipulation, and resource locking (collision avoidance). RFC 2518 was published in February 1999, and this specification obsoletes RFC 2518 with minor revisions mostly due to interoperability experience. {[}STANDARDS-TRACK{]}},
}

@misc{rfc7230,
	series =	{Request for Comments},
	number =	7230,
	howpublished =	{RFC 7230},
	publisher =	{RFC Editor},
	doi =		{10.17487/RFC7230},
	url =		{https://www.rfc-editor.org/info/rfc7230},
        author =	{Roy T. Fielding and Julian Reschke},
	title =		{{Hypertext Transfer Protocol (HTTP/1.1): Message Syntax and Routing}},
	pagetotal =	89,
	year =		2014,
	month =		jun,
	abstract =	{The Hypertext Transfer Protocol (HTTP) is a stateless application-level protocol for distributed, collaborative, hypertext information systems. This document provides an overview of HTTP architecture and its associated terminology, defines the "http" and "https" Uniform Resource Identifier (URI) schemes, defines the HTTP/1.1 message syntax and parsing requirements, and describes related security concerns for implementations.},
}

@misc{rfc7231,
	series =	{Request for Comments},
	number =	7231,
	howpublished =	{RFC 7231},
	publisher =	{RFC Editor},
	doi =		{10.17487/RFC7231},
	url =		{https://www.rfc-editor.org/info/rfc7231},
        author =	{Roy T. Fielding and Julian Reschke},
	title =		{{Hypertext Transfer Protocol (HTTP/1.1): Semantics and Content}},
	pagetotal =	101,
	year =		2014,
	month =		jun,
	abstract =	{The Hypertext Transfer Protocol (HTTP) is a stateless \textbackslash{}\%application- level protocol for distributed, collaborative, hypertext information systems. This document defines the semantics of HTTP/1.1 messages, as expressed by request methods, request header fields, response status codes, and response header fields, along with the payload of messages (metadata and body content) and mechanisms for content negotiation.},
}

@misc{rfc7232,
	series =	{Request for Comments},
	number =	7232,
	howpublished =	{RFC 7232},
	publisher =	{RFC Editor},
	doi =		{10.17487/RFC7232},
	url =		{https://www.rfc-editor.org/info/rfc7232},
        author =	{Roy T. Fielding and Julian Reschke},
	title =		{{Hypertext Transfer Protocol (HTTP/1.1): Conditional Requests}},
	pagetotal =	28,
	year =		2014,
	month =		jun,
	abstract =	{The Hypertext Transfer Protocol (HTTP) is a stateless application- level protocol for distributed, collaborative, hypertext information systems. This document defines HTTP/1.1 conditional requests, including metadata header fields for indicating state changes, request header fields for making preconditions on such state, and rules for constructing the responses to a conditional request when one or more preconditions evaluate to false.},
}


@article{anand2013orchestrated,
title = "An orchestrated survey of methodologies for automated software test case generation",
journal = "Journal of Systems and Software",
volume = "86",
number = "8",
pages = "1978 - 2001",
year = "2013",
issn = "0164-1212",
doi = "https://doi.org/10.1016/j.jss.2013.02.061",
url = "http://www.sciencedirect.com/science/article/pii/S0164121213000563",
author = "Saswat Anand and Edmund K. Burke and Tsong Yueh Chen and John Clark and Myra B. Cohen and Wolfgang Grieskamp and Mark Harman and Mary Jean Harrold and Phil McMinn and Antonia Bertolino and J. Jenny Li and Hong Zhu",
keywords = "Adaptive random testing, Combinatorial testing, Model-based testing, Orchestrated survey, Search-based software testing, Software testing, Symbolic execution, Test automation, Test case generation",
abstract = "Test case generation is among the most labour-intensive tasks in software testing. It also has a strong impact on the effectiveness and efficiency of software testing. For these reasons, it has been one of the most active research topics in software testing for several decades, resulting in many different approaches and tools. This paper presents an orchestrated survey of the most prominent techniques for automatic generation of software test cases, reviewed in self-standing sections. The techniques presented include: (a) structural testing using symbolic execution, (b) model-based testing, (c) combinatorial testing, (d) random testing and its variant of adaptive random testing, and (e) search-based testing. Each section is contributed by world-renowned active researchers on the technique, and briefly covers the basic ideas underlying the method, the current state of the art, a discussion of the open research problems, and a perspective of the future development of the approach. As a whole, the paper aims at giving an introductory, up-to-date and (relatively) short overview of research in automatic test case generation, while ensuring a comprehensive and authoritative treatment."
}

@inproceedings{testing-dropbox,
  author    = {John Hughes and
               Benjamin C. Pierce and
               Thomas Arts and
               Ulf Norell},
  title     = {Mysteries of DropBox: Property-Based Testing of a Distributed Synchronization
               Service},
  booktitle = {2016 {IEEE} International Conference on Software Testing, Verification
               and Validation, {ICST} 2016, Chicago, IL, USA, April 11-15, 2016},
  pages     = {135--145},
  year      = {2016},
  url       = {https://doi.org/10.1109/ICST.2016.37},
  doi       = {10.1109/ICST.2016.37},
  timestamp = {Wed, 24 May 2017 08:30:36 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/icst/HughesPAN16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{pbt,
author = {Fink, George and Bishop, Matt},
title = {Property-Based Testing: A New Approach to Testing for Assurance},
year = {1997},
issue_date = {July 1997},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {22},
number = {4},
issn = {0163-5948},
url = {https://doi.org/10.1145/263244.263267},
doi = {10.1145/263244.263267},
abstract = {The goal of software testing analysis is to validate that an implementation satisfies its specifications. Many errors in software are caused by generalizable flaws in the source code. Property-based testing assures that a given program is free of specified generic flaws. Property-based testing uses property specifications and a data-flow analysis of the program to guide evaluation of test executions for correctness and completeness.},
journal = {SIGSOFT Softw. Eng. Notes},
month = jul,
pages = {74–80},
numpages = {7}
}

@inproceedings{BohannonPierce10,
  author = {Aaron Bohannon and Benjamin C. Pierce},
  title = {Featherweight {F}irefox:
                  {F}ormalizing the Core of a Web Browser},
  booktitle = {Usenix Conference on Web Application Development (WebApps)},
  year = {2010},
  month = jun,
  keys = {security},
  short = {http://www.cis.upenn.edu/~bcpierce/papers/webapps_2010_bohannon_final.pdf}
}

@inproceedings{Bohannon&09,
  author = {Bohannon, Aaron and Pierce, Benjamin C. and Sj\"{o}berg, Vilhelm and Weirich, Stephanie and Zdancewic, Steve},
  title = {Reactive Noninterference},
  booktitle = {CCS '09: Proceedings of the 16th ACM conference on Computer and communications security},
  year = {2009},
  isbn = {978-1-60558-894-0},
  pages = {79--90},
  location = {Chicago, Illinois, USA},
  doi = {},
  publisher = {ACM},
  address = {New York, NY, USA},
  keys = {security}
}

@InProceedings{ramon2019,
author="Janssen, Ramon
and Vaandrager, Frits
and Tretmans, Jan",
editor="Ahrendt, Wolfgang
and Tapia Tarifa, Silvia Lizeth",
title="Relating Alternating Relations for Conformance and Refinement",
booktitle="Integrated Formal Methods",
year="2019",
publisher="Springer International Publishing",
address="Cham",
pages="246--264",
isbn="978-3-030-34968-4"
}

@inproceedings{qc,
author = {Claessen, Koen and Hughes, John},
title = {QuickCheck: A Lightweight Tool for Random Testing of Haskell Programs},
year = {2000},
isbn = {1581132026},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/351240.351266},
doi = {10.1145/351240.351266},
abstract = {Quick Check is a tool which aids the Haskell programmer in formulating and testing properties of programs. Properties are described as Haskell functions, and can be automatically tested on random input, but it is also possible to define custom test data generators. We present a number of case studies, in which the tool was successfully used, and also point out some pitfalls to avoid. Random testing is especially suitable for functional programs because properties can be stated at a fine grain. When a function is built from separately tested components, then random testing suffices to obtain good coverage of the definition under test.},
booktitle = {Proceedings of the Fifth ACM SIGPLAN International Conference on Functional Programming},
pages = {268–279},
numpages = {12},
series = {ICFP '00}
}

@inproceedings{claessen2002,
author = {Claessen, Koen and Hughes, John},
title = {Testing Monadic Code with QuickCheck},
year = {2002},
isbn = {1581136056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/581690.581696},
doi = {10.1145/581690.581696},
booktitle = {Proceedings of the 2002 ACM SIGPLAN Workshop on Haskell},
pages = {65–77},
numpages = {13},
location = {Pittsburgh, Pennsylvania},
series = {Haskell ’02}
}

@article{Tretmans,
title = "Conformance testing with labelled transition systems: Implementation relations and test generation",
journal = "Computer Networks and ISDN Systems",
volume = "29",
number = "1",
pages = "49 - 79",
year = "1996",
note = "Protocol Testing",
issn = "0169-7552",
doi = "https://doi.org/10.1016/S0169-7552(96)00017-7",
url = "http://www.sciencedirect.com/science/article/pii/S0169755296000177",
author = "Jan Tretmans",
keywords = "Communication protocols, Formal description techniques, Transition systems, Conformance, Conformance testing, Test case generation",
abstract = "This paper studies testing based on labelled transition systems, presenting two test generation algorithms with their corresponding implementation relations. The first algorithm assumes that implementations communicate with their environment via symmetric, synchronous interactions. It is based on the theory of testing equivalence and preorder, as is most of the testing theory for labelled transition systems, and it is found in the literature in some slightly different variations. The second algorithm is based on the assumption that implementations communicate with their environment via inputs and outputs. Such implementations are formalized by restricting the class of labelled transition systems to those systems that can always accept input actions. For these implementations a testing theory is developed, analogous to the theory of testing equivalence and preorder. It consists of implementation relations formalizing the notion of conformance of these implementations with respect to labelled transition system specifications, test cases and test suites, test execution, the notion of passing a test suite, and the test generation algorithm, which is proved to produce sound test suites for one of the implementation relations."
}

@Inbook{Brinksma1997,
author="Brinksma, Ed
and Heerink, Lex
and Tretmans, Jan",
editor="Kim, Myungchul
and Kang, Sungwon
and Hong, Keesoo",
title="Developments in testing transition systems",
bookTitle="Testing of Communicating Systems: IFIP TC6 10th International Workshop on Testing of Communicating Systems, 8--10 September 1997, Cheju Island, Korea",
year="1997",
publisher="Springer US",
address="Boston, MA",
pages="143--166",
abstract="This paper discusses some of the developments in the theory of test generation from labelled transition systems over the last decade, and puts these devel­opments in a historical perspective. These developments are driven by the need to make testing theory applicable to realistic systems. We illustrate the developments that have taken place in a chronological order, and we discuss the main motivations that led to these developments. In this paper the claim is made that testing theory (slowly) narrows the gap with testing practice, and that progress is made in designing test generation algorithms that can be used in realistic situations while maintaining a sound theoretical basis.",
isbn="978-0-387-35198-8",
doi="10.1007/978-0-387-35198-8_10",
url="https://doi.org/10.1007/978-0-387-35198-8_10"
}

@Inbook{Brinksma2001,
author="Brinksma, Ed
and Tretmans, Jan",
title="Testing Transition Systems: An Annotated Bibliography",
bookTitle="Modeling and Verification of Parallel Processes: 4th Summer School, MOVEP 2000 Nantes, France, June 19--23, 2000 Revised Tutorial Lectures",
year="2001",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="187--195",
abstract="Labelled transition system based test theory has made remarkable progress over the past 15 years. From a theoretically interesting approach to the semantics of reactive systems it has developed into a field where testing theory is (slowly) narrowing the gap with testing practice. In particular, new test generation algorithms are being designed that can be used in realistic situations whilst maintaining a sound theoretical basis. In this paper we present an annotated bibliography of labelled transition system based test theory and its applications covering the main developments.",
isbn="978-3-540-45510-3",
doi="10.1007/3-540-45510-8_9",
url="https://doi.org/10.1007/3-540-45510-8_9"
}


@inproceedings{torxakis-dropbox,
  title={Model-Based Testing with TorXakis: The Mysteries of Dropbox Revisited},
  author={Tretmans, Jan and van de Laar, Pi\"erre},
  booktitle={Strahonja, V.(ed.), CECIIS: 30th Central European Conference on Information and Intelligent Systems, October 2-4, 2019, Varazdin, Croatia. Proceedings},
  pages={247--258},
  year={2019},
  organization={Zagreb: Faculty of Organization and Informatics, University of Zagreb}
}

@software{TorXakis,
author = {Tretmans, Jan and van de Laar, Piërre},
license = {BSD-3-Clause},
title = {{TorXakis}},
url = {https://github.com/TorXakis/Torxakis}
}

@inproceedings{Bochmann1989,
author = {von Bochmann, Gregor and Bellal, Omar},
booktitle = {Proc. 2nd Int. Workshop on Protocol Test Systems, Berlin},
pages = {272--294},
title = {{Test result analysis with respect to formal specifications}},
year = {1989}
}

@inproceedings{bdd90,
  title={Test result analysis and validation of test verdicts},
  author={von Bochmann, Gregor and Desbiens, D and Duboc, M and Ouimet, Devin and Saba, F},
  booktitle={3rd Int. Workshop on Protocol Test Systems},
  year={1991}
}

@INPROCEEDINGS{Wu89,
author={Wu, Cheng and von Bochmann, Gregor},
booktitle={[Proceedings] GLOBECOM '90: IEEE Global Telecommunications Conference and Exhibition},
title={An execution model for LOTOS specifications},
year={1990},
volume={},
number={},
pages={1890-1895 vol.3},
abstract={A model for executing LOTOS (language of temporal ordering specification) specifications (temporal control part) is described. It is based on an activity tree with attributes. The activity tree reflects the dynamic relations between the process invocations and activations of behavior expressions in the specified system, while functions related to the attributes control the execution of interactions and the growing and updating of the tree. The problem of infinite branching, which is caused by non-well-guarded specifications or specifications containing generalized choices, is discussed based on the strategies for growing the activity tree. The general execution model described can also be used as a basis for designing LOTOS implementaton strategies for distributed environments or for systems with parallel processors.<>},
keywords={distributed processing;parallel processing;specification languages;growing strategies;execution model;LOTOS;language of temporal ordering specification;temporal control part;activity tree;behavior expressions;attributes;infinite branching;distributed environments;parallel processors;Open systems;Control systems;Protocols;Communication system control;Carbon capture and storage;Specification languages;Computer languages},
doi={10.1109/GLOCOM.1990.116809},
ISSN={null},
month={Dec},}

@article{Castro1991,
title = "The relationship between conformance testing of and interoperability between OSI systems",
journal = "Computer Standards \& Interfaces",
volume = "12",
number = "1",
pages = "3 - 11",
year = "1991",
issn = "0920-5489",
doi = "https://doi.org/10.1016/0920-5489(91)90046-3",
url = "http://www.sciencedirect.com/science/article/pii/0920548991900463",
author = "Stephen Castro",
keywords = "Conformance testing, interoperability, Open Systems Interconnect, protocols",
abstract = "As a part of the COS Interoperability Research Program, this paper serves as a first step toward understanding the complex theoretical problem of interoperability prediction via conformance testing of implementations of OSI protocols. More importantly, it serves as the motivation for, and rationale behind, a prototyping project currently under development at COS. We first provide a subject index for an annotated bibliography of conformance and interoperability testing research, and a brief background discussion on testcase selection. We then define a formalism and subsequently describe and analyze the role of conformance testing in predicting interoperability. We conclude by identifying basic requirements of protocol testing architectures whose aim is to ‘increase the likelihood’ of interoperability."
}

@article{vst,
author = {Cao, Qinxiang and Beringer, Lennart and Gruetter, Samuel and Dodds, Josiah and Appel, Andrew W},
doi = {10.1007/s10817-018-9457-5},
issn = {0168-7433},
journal = {Journal of Automated Reasoning},
month = {jun},
number = {1-4},
pages = {367--422},
title = {{VST-Floyd: A Separation Logic Tool to Verify Correctness of C Programs}},
url = {http://link.springer.com/10.1007/s10817-018-9457-5},
volume = {61},
year = {2018}
}

@article{netsem,
author = {Bishop, Steve and Fairbairn, Matthew and Mehnert, Hannes and Norrish, Michael and Ridge, Tom and Sewell, Peter and Smith, Michael and Wansbrough, Keith},
title = {Engineering with Logic: Rigorous Test-Oracle Specification and Validation for TCP/IP and the Sockets API},
year = {2018},
issue_date = {January 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {66},
number = {1},
issn = {0004-5411},
url = {https://doi.org/10.1145/3243650},
doi = {10.1145/3243650},
journal = {J. ACM},
month = dec,
articleno = {Article 1},
numpages = {77},
keywords = {Rigorous engineering, specification, network protocols}
}

@article{deepspec,
abstract = {We introduce our efforts within the project ‘The science of deep specification' to work out the key formal underpinnings of industrial-scale formal specifications of software and hardware components, anticipating a world where large verified systems are routinely built out of smaller verified components that are also used by many other projects. We identify an important class of specification that has already been used in a few experiments that connect strong component-correctness theorems across the work of different teams. To help popularize the unique advantages of that style, we dub it deep specification, and we say that it encompasses specifications that are rich, two-sided, formal and live (terms that we define in the article). Our core team is developing a proof-of-concept system (based on the Coq proof assistant) whose specification and verification work is divided across largely decoupled subteams at our four institutions, encompassing hardware microarchitecture, compilers, operating systems and applications, along with cross-cutting principles and tools for effective specification. We also aim to catalyse interest in the approach, not just by basic researchers but also by users in industry. This article is part of the themed issue ‘Verified trustworthy software systems'.},
author = {Appel, Andrew W. and Beringer, Lennart and Chlipala, Adam and Pierce, Benjamin C. and Shao, Zhong and Weirich, Stephanie and Zdancewic, Steve},
doi = {10.1098/rsta.2016.0331},
file = {::},
issn = {1364-503X},
journal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
keywords = {Formal methods,Programming languages,Proof assistants},
month = {oct},
number = {2104},
pages = {20160331},
publisher = {Royal Society Publishing},
title = {{Position paper: the science of deep specification}},
url = {https://royalsocietypublishing.org/doi/10.1098/rsta.2016.0331},
volume = {375},
year = {2017}
}

@article{estelle,
title = "An introduction to Estelle: A specification language for distributed systems",
journal = "Computer Networks and ISDN Systems",
volume = "14",
number = "1",
pages = "3 - 23",
year = "1987",
issn = "0169-7552",
doi = "https://doi.org/10.1016/0169-7552(87)90084-5",
url = "http://www.sciencedirect.com/science/article/pii/0169755287900845",
author = "S. Budkowski and P. Dembinski",
keywords = "Estelle, Formal Description Technique, FDT, Distributed Systems, Specification Language, Communication Protocols, Services, Open System Interconnection, OSI",
abstract = "Estelle is a Formal Description Technique, defined within ISO (International Organization for Standardization) for specification of distributed, concurrent information processing systems. In particular, Estelle can be used to describe the services and protocols of the layers of Open Systems Interconnection (OSI) architecture defined by ISO. Its present ISO status is Draft International Standard (DIS 9074). The article outlines syntactic and semantic aspects of this description technique."
}

@inproceedings{broy2005model,
  title={Model-based testing of reactive systems},
  author={Broy, Manfred and Jonsson, Bengt and Katoen, J-P and Leucker, Martin and Pretschner, Alexander},
  booktitle={Volume 3472 of Springer LNCS},
  year={2005},
  organization={Springer}
}

@misc{hartman2006model,
  title={Model based test generation for validation of parallel and concurrent software},
  author={Hartman, Alan and Kirshin, Andrei and Nagin, Kenneth and Olvovsky, Sergey and Zlotnick, Aviad},
  year={2006},
  month=aug # "~8",
  note={US Patent 7,089,534}
}

@article{Aichernig2019,
abstract = {Property-based testing is well suited for web-service applications, which was already shown in various case studies. For example, it has been demonstrated that JSON schemas can be used to automatically derive test case generators for web forms. In this work, we present a test case generation approach for a rule engine-driven web-service application. Business-rule models serve us as input for property-based testing. We parse these models to automatically derive generators for sequences of web-service requests together with their required form data. Property-based testing is mostly applied in the context of functional programming. Here, we define our properties in an object-oriented style in C{\#} and its tool FsCheck. We apply our method to the business-rule models of an industrial web-service application in the automotive domain.},
author = {Aichernig, Bernhard K and Schumi, Richard},
doi = {10.1007/s10270-017-0647-0},
issn = {1619-1366},
journal = {Software {\&} Systems Modeling},
month = {apr},
number = {2},
pages = {889--911},
title = {{Property-based testing of web services by deriving properties from business-rule models}},
url = {https://doi.org/10.1007/s10270-017-0647-0},
volume = {18},
year = {2019}
}

@misc{quickrest,
    title={QuickREST: Property-based Test Generation of OpenAPI-Described RESTful APIs},
    author={Stefan Karlsson and Adnan Causevic and Daniel Sundmark},
    year={2019},
    eprint={1912.09686},
    archivePrefix={arXiv},
    primaryClass={cs.SE}
}

@article{zookeeper,
author = {Artho, Cyrille and Banzai, Kazuaki and Gros, Quentin and Rousset, Guillaume and Ma, Lei and Kitamura, Takashi and Hagiya, Masami and Tanabe, Yoshinori and Yamamoto, Mitsuharu},
title = {Model-based testing of Apache ZooKeeper: Fundamental API usage and watchers},
journal = {Software Testing, Verification and Reliability},
volume = {n/a},
number = {n/a},
pages = {e1720},
keywords = {Apache ZooKeeper, asynchronous systems, concurrency, model-based testing, networked systems, trigger},
doi = {10.1002/stvr.1720},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/stvr.1720},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/stvr.1720},
note = {e1720 stvr.1720},
abstract = {Summary In this paper, we extend work on model-based testing for Apache ZooKeeper, to handle watchers (triggers) and improve scalability. In a distributed asynchronous shared storage like ZooKeeper, watchers deliver notifications on state changes. They are difficult to test because watcher notifications involve an initial action that sets the watcher, followed by another action that changes the previously seen state. We show how to generate test cases for concurrent client sessions executing against ZooKeeper with the tool Modbat. The tests are verified against an oracle that takes into account all possible timings of network communication. The oracle has to verify that there exists a chain of events that triggers both the initial callback and the subsequent watcher notification. We show in detail how the oracle computes whether watch triggers are correct and how the model was adapted and improved to handle these features. Together with a new search improvement that increases both speed and accuracy, we are able to verify large test setups and confirm several defects with our model.}
}

@inproceedings{STG,
author = {Clarke, Duncan and J\'{e}ron, Thierry and Rusu, Vlad and Zinovieva, Elena},
title = {STG: A Tool for Generating Symbolic Test Programs and Oracles from Operational Specifications},
year = {2001},
isbn = {1581133901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.library.upenn.edu/10.1145/503209.503252},
doi = {10.1145/503209.503252},
abstract = {We report on a tool we have developed that automates the derivation of tests from specifications. The tool implements conformance testing techniques to derive symbolic tests that incorporate their own oracles from formal operational specifications. It was applied for testing a simple version of the CEPS (Common Electronic Purse Specification).},
booktitle = {Proceedings of the 8th European Software Engineering Conference Held Jointly with 9th ACM SIGSOFT International Symposium on Foundations of Software Engineering},
pages = {301–302},
numpages = {2},
location = {Vienna, Austria},
series = {ESEC/FSE-9}
}

@InProceedings{IOSTS,
author="Rusu, Vlad
and du Bousquet, Lydie
and J{\'e}ron, Thierry",
editor="Grieskamp, Wolfgang
and Santen, Thomas
and Stoddart, Bill",
title="An Approach to Symbolic Test Generation",
booktitle="Integrated Formal Methods",
year="2000",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="338--357",
abstract="Test generation is a program-synthesis problem: starting from the formal specification of a system under test, and from a test purpose describing a set of behaviours to be tested, compute a reactive program that observes an implementation of the system to detect non- conformant behaviour, while trying to control it towards satisfying the test purpose. In this paper we describe an approach for generating sym- bolic test cases, in the form of input-output automata with variables and parameters.",
isbn="978-3-540-40911-3"
}

@inproceedings{pkt-dyn,
author = {Sun, Wei and Xu, Lisong and Elbaum, Sebastian},
title = {Improving the Cost-Effectiveness of Symbolic Testing Techniques for Transport Protocol Implementations under Packet Dynamics},
year = {2017},
isbn = {9781450350761},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3092703.3092706},
doi = {10.1145/3092703.3092706},
abstract = { The majority of Internet traffic is transferred by transport protocols. The correctness of these transport protocol implementations is hard to validate as their behaviors depend not only on their protocols but also on their network environments that can introduce dynamic packet delay and loss. Random testing, widely used in industry due to its simplicity and low cost, struggles to detect packet delay related faults which occur with low probability. Symbolic execution based testing is promising at detecting such low probability faults, but it requires large testing budgets as it attempts to cover a prohibitively large input space of packet dynamics. To improve its cost-effectiveness, we propose two domain-specific heuristic techniques, called packet retransmission based priority and network state based priority, which are motivated by two common transport protocol properties. In our experiments using the Linux TFTP programs, our techniques improve the cost-effectiveness of symbolic execution based testing for transport protocols, detecting three times as many faults when the budget is in the range of minutes and hours. },
booktitle = {Proceedings of the 26th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {79–89},
numpages = {11},
keywords = {automated testing, symbolic execution, testing packet dynamics, Network protocol validation},
location = {Santa Barbara, CA, USA},
series = {ISSTA 2017}
}

@ARTICLE{Apache,
  author={Fielding, Roy T. and Kaiser, Gail},
  journal={IEEE Internet Computing},
  title={The Apache HTTP Server Project},
  year={1997},
  volume={1},
  number={4},
  pages={88-90},
  abstract={Most reports of Internet collaboration refer to small scale operations among a few authors or designers. However, several projects have shown that the Internet can also be the locus for large scale collaboration. In these projects, contributors from around the world combine their individual forces and develop a product that rivals those of multibillion dollar corporations. The Apache HTTP Server Project is a case in point. This collaborative software development effort has created a robust, feature-rich HTTP server software package that currently dominates the public Internet market (46 percent compared with 16 percent for Microsoft and 12 percent for Netscape, according to a June 1997 survey published by Netcraft). The software and its source code are free, but Apache's popularity is more often attributed to performance than price. The project is managed by the Apache Group, a geographically distributed group of volunteers who use the Internet and Web to communicate, develop, and distribute the server and its related documentation. In addition, hundreds of users have contributed ideas, code, and documentation to the project.},
  keywords={Internet;network servers;protocols;Apache HTTP Server Project;Internet collaboration;large scale collaboration;collaborative software development effort;feature-rich HTTP server software package;public Internet market;source code;Apache Group;Web;Web server;Internet;Collaboration;Documentation;Large-scale systems;Collaborative software;Robustness;Software packages;Software performance;Project management},
  doi={10.1109/4236.612229},
  ISSN={1941-0131},
  month={July},}

@url{nginx,
title={Nginx},
url={http://nginx.org/},
author={Sysoev, Igor}
}

@url{nginx242,
   title={DAV module does not respect if-unmodified-since},
   url={https://trac.nginx.org/nginx/ticket/242},
   author={Haverbeke, Marijn},
   year={2012},
   month={Nov}}

@INPROCEEDINGS{Artho2013,
  author={Artho, Cyrille and Hagiya, Masami and Potter, Richard and Tanabe, Yoshinori and Weitl, Franz and Yamamoto, Mitsuharu},
  booktitle={2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)},
  title={Software model checking for distributed systems with selector-based, non-blocking communication},
  year={2013},
  volume={},
  number={},
  pages={169-179},
  abstract={Many modern software systems are implemented as client/server architectures, where a server handles multiple clients concurrently. Testing does not cover the outcomes of all possible thread and communication schedules reliably. Software model checking, on the other hand, covers all possible outcomes but is often limited to subsets of commonly used protocols and libraries. Earlier work in cache-based software model checking handles implementations using socket-based TCP/IP networking, with one thread per client connection using blocking input/output. Recently, servers using non-blocking, selector-based input/output have become prevalent. This paper describes our work extending the Java PathFinder extension net-iocache to such software, and the application of our tool to modern server software.},
  keywords={},
  doi={10.1109/ASE.2013.6693077},
  ISSN={},
  month={Nov},}

@article{Modbat,
   title={Model-based Testing of the Java Network API},
   volume={245},
   ISSN={2075-2180},
   url={http://dx.doi.org/10.4204/EPTCS.245.4},
   DOI={10.4204/eptcs.245.4},
   journal={Electronic Proceedings in Theoretical Computer Science},
   publisher={Open Publishing Association},
   author={Artho, Cyrille and Rousset, Guillaume},
   year={2017},
   month={Mar},
   pages={46–51}
}

@inproceedings{Barlas2007,
author = {Barlas, Elliot and Bultan, Tevfik},
title = {Netstub: A Framework for Verification of Distributed Java Applications},
year = {2007},
isbn = {9781595938824},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1321631.1321638},
doi = {10.1145/1321631.1321638},
abstract = {Automated verification of distributed programs is a challenging problem. Since the behavior of a distributed program encompasses the behavior of the network, possible configurations of the network have to be investigated during verification. This leads to very large state spaces, and automated verification becomes infeasible. We present a framework that addresses this problem by decoupling the behavior of distributed programs from the behavior of the network. Our framework is based on a set of stub classes that replace native methods used in network communication and enables verification of distributed Java applications by isolating their behavior from the network. The framework supports two modes of verification: unit verification and integration verification. Integration verification checks multiple interacting distributed application components by running them in a single JVM and simulating the behavior of the network within the same JVM via stub classes. Unit verification targets a single component of a distributed application and requires that the user write an event generator class that utilizes the API exported by the framework. While unit verification only checks a single application component, it benefits from a greatly reduced state space compared do that of integration verification},
booktitle = {Proceedings of the Twenty-Second IEEE/ACM International Conference on Automated Software Engineering},
pages = {24–33},
numpages = {10},
keywords = {automated verification, testing and verification of, model checking},
location = {Atlanta, Georgia, USA},
series = {ASE '07}
}

@inproceedings{musuvathi2004model,
  title={Model checking large network protocol implementations},
  author={Musuvathi, Madanlal and Engler, Dawson R.},
  booktitle={Proc. 1st Conf. on Symposium on Networked Systems Design and Implementation (NSDI'04), Berkeley, CA, USA},
  pages={12--12},
  year={2004}
}

@InProceedings{Sobeih2005,
author="Sobeih, Ahmed
and Viswanathan, Mahesh
and Marinov, Darko
and Hou, Jennifer C.",
editor="Lau, Kung-Kiu
and Banach, Richard",
title="Finding Bugs in Network Protocols Using Simulation Code and Protocol-Specific Heuristics",
booktitle="Formal Methods and Software Engineering",
year="2005",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="235--250",
abstract="Traditional network simulators perform well in evaluating the performance of network protocols but lack the capability of verifying the correctness of protocols. To address this problem, we have extended the J-Sim network simulator with a model checking capability that explores the state space of a network protocol to find an execution that violates a safety invariant. In this paper, we demonstrate the usefulness of this integrated tool for verification and performance evaluation by analyzing two widely used and important network protocols: AODV and directed diffusion. Our analysis discovered a previously unknown bug in the J-Sim implementation of AODV. More importantly, we also discovered a serious deficiency in directed diffusion. To enable the analysis of these fairly complex protocols, we needed to develop protocol-specific search heuristics that guide state-space exploration. We report our findings on discovering good search heuristics to analyze network protocols similar to AODV and directed diffusion.",
isbn="978-3-540-32250-4"
}

@inproceedings{Lopez2015,
author = {L\'{o}pez, Hugo A. and Marques, Eduardo R. B. and Martins, Francisco and Ng, Nicholas and Santos, C\'{e}sar and Vasconcelos, Vasco Thudichum and Yoshida, Nobuko},
title = {Protocol-Based Verification of Message-Passing Parallel Programs},
year = {2015},
isbn = {9781450336895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2814270.2814302},
doi = {10.1145/2814270.2814302},
abstract = { We present ParTypes, a type-based methodology for the verification of Message Passing Interface (MPI) programs written in the C programming language. The aim is to statically verify programs against protocol specifications, enforcing properties such as fidelity and absence of deadlocks. We develop a protocol language based on a dependent type system for message-passing parallel programs, which includes various communication operators, such as point-to-point messages, broadcast, reduce, array scatter and gather. For the verification of a program against a given protocol, the protocol is first translated into a representation read by VCC, a software verifier for C. We successfully verified several MPI programs in a running time that is independent of the number of processes or other input parameters. This contrasts with alternative techniques, notably model checking and runtime verification, that suffer from the state-explosion problem or that otherwise depend on parameters to the program itself. We experimentally evaluated our approach against state-of-the-art tools for MPI to conclude that our approach offers a scalable solution. },
booktitle = {Proceedings of the 2015 ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications},
pages = {280–298},
numpages = {19},
keywords = {Program verification, Dependent types, MPI, Session types, Parallel programming},
location = {Pittsburgh, PA, USA},
series = {OOPSLA 2015}
}

@InProceedings{itp21,
  author =	{Zhang, Hengchu and Honor\'{e}, Wolf and Koh, Nicolas and Li, Yao and Li, Yishuai and Xia, Li-Yao and Beringer, Lennart and Mansky, William and Pierce, Benjamin and Zdancewic, Steve},
  title =	{{Verifying an HTTP Key-Value Server with Interaction Trees and VST}},
  booktitle =	{12th International Conference on Interactive Theorem Proving (ITP 2021)},
  pages =	{32:1--32:19},
  series =	{Leibniz International Proceedings in Informatics (LIPIcs)},
  ISBN =	{978-3-95977-188-7},
  ISSN =	{1868-8969},
  year =	{2021},
  volume =	{193},
  editor =	{Cohen, Liron and Kaliszyk, Cezary},
  publisher =	{Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik},
  address =	{Dagstuhl, Germany},
  URL =		{https://drops.dagstuhl.de/opus/volltexte/2021/13927},
  URN =		{urn:nbn:de:0030-drops-139273},
  doi =		{10.4230/LIPIcs.ITP.2021.32},
  annote =	{Keywords: formal verification, Coq, HTTP, deep specification}
}

@incollection{coinduction,
  title = {Infinite Data and Proofs},
  booktitle = {Certified Programming with Dependent Types},
  author = {Adam Chlipala},
  year = {2017},
  url = {http://adam.chlipala.net/cpdt/html/Cpdt.Coinductive.html},
  publisher = {MIT Press}
}

@article{gengood,
author = {Lampropoulos, Leonidas and Paraskevopoulou, Zoe and Pierce, Benjamin C.},
title = {Generating Good Generators for Inductive Relations},
year = {2017},
issue_date = {January 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {POPL},
url = {https://doi.org/10.1145/3158133},
doi = {10.1145/3158133},
abstract = {Property-based random testing (PBRT) is widely used in the functional programming and verification communities. For testing simple properties, PBRT tools such as QuickCheck can automatically generate random inputs of a given type. But for more complex properties, effective testing often demands generators for random inputs that belong to a given type and satisfy some logical condition. QuickCheck provides a library of combinators for building such generators by hand, but this can be tedious for simple conditions and error prone for more complex ones. Fortunately, the process can often be automated. The most prominent method, narrowing, works by traversing the structure of the condition, lazily instantiating parts of the data structure as constraints involving them are met.  We show how to use ideas from narrowing to compile a large subclass of Coq's inductive relations into efficient generators, avoiding the interpretive overhead of previous implementations. More importantly, the same compilation technique allows us to produce proof terms certifying that each derived generator is good---i.e., sound and complete with respect to the inductive relation it was derived from. We implement our algorithm as an extension of QuickChick, an existing tool for property-based testing in Coq. We evaluate our method by automatically deriving good generators for the majority of the specifications in Software Foundations, a formalized textbook on programming language foundations.},
journal = {Proc. ACM Program. Lang.},
month = {dec},
articleno = {45},
numpages = {30},
keywords = {Coq, Narrowing, Property-based Testing, QuickCheck, QuickChick, Random Testing}
}

@book{tapl,
  author = {Benjamin C. Pierce},
  title = {Types and Programming Languages},
  publisher = {MIT Press},
  year = 2002,
  plclub = {Yes},
  bcp = {Yes},
  keys = {books},
  homepage = {http://www.cis.upenn.edu/~bcpierce/tapl},
  errata = {http://www.cis.upenn.edu/~bcpierce/tapl/errata.txt}
}

@url{http-stats,
  author={W3Techs},
  title={Historical trends in the usage statistics of web servers},
  url={https://w3techs.com/technologies/history_overview/web_server}
}

@url{http-netcraft,
  title={Web server survey},
  url={https://news.netcraft.com/archives/category/web-server-survey/},
  author={Netcraft},
  year={2022},
  month={Mar},
  date={29}
}

@InProceedings{unison,
author="Pierce, Benjamin C.
and Vouillon, J{\'e}r{\^o}me",
editor="Kobayashi, Naoki
and Pierce, Benjamin C.",
title="Unison: A File Synchronizer and Its Specification",
booktitle="Theoretical Aspects of Computer Software",
year="2001",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="560--560",
abstract="File synchronizers are tools that reconcile disconnected modifications to replicated directory structures. Like other replication and reconciliation facilities provided by modern operating systems and middleware layers, trustworthy synchronizers are notoriously difficult to build: they must deal correctly with both the semantic complexities of file systems and the unpredictable failure modes arising from distributed operation. On the other hand, synchronizers are simpler than most of their relatives in that they operate as stand-alone, user-level utilities, whose intended behavior is relatively easy to isolate from the other functions of the system. This combination of subtlety and isolation makes synchronizers attractive candidates for precise mathematical specification.",
isbn="978-3-540-45500-4"
}

@inproceedings{what-sync,
author = {Balasubramaniam, S. and Pierce, Benjamin C.},
title = {What is a File Synchronizer?},
year = {1998},
isbn = {158113035X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/288235.288261},
doi = {10.1145/288235.288261},
booktitle = {Proceedings of the 4th Annual ACM/IEEE International Conference on Mobile Computing and Networking},
pages = {98–108},
numpages = {11},
location = {Dallas, Texas, USA},
series = {MobiCom '98}
}

@Misc{posix,
  author =       "{IEEE}",
  title =        "{IEEE Std 1003.1-2017: POSIX.1a}",
  howpublished = "Web document",
  year =         "2017",
  bibdate =      "Fri Sep 10 13:34:10 2021",
  bibsource =    "http://www.math.utah.edu/pub/tex/bib/ieeestd.bib",
  note =         "POSIX.1-2017 is a revision of IEEE Std 1003.1-2008,
                 and replaces previous versions of 2008, 2013, and 2016.
                 Also issued as The Open Group Technical Standard Base
                 Specifications, Issue 7.",
  URL =          "https://pubs.opengroup.org/onlinepubs/9699919799/",
  acknowledgement = ack-nhfb,
}

@article{lotos,
title = "Introduction to the ISO specification language LOTOS",
journal = "Computer Networks and ISDN Systems",
volume = "14",
number = "1",
pages = "25 - 59",
year = "1987",
issn = "0169-7552",
doi = "https://doi.org/10.1016/0169-7552(87)90085-7",
url = "http://www.sciencedirect.com/science/article/pii/0169755287900857",
author = "Tommaso Bolognesi and Ed Brinksma",
keywords = "Concurrent languages, Formal Description Techniques, Open Systems Interconnection, Protocol Specification, Specification Languages",
abstract = "LOTOS is a specification language that has been specifically developed for the formal description of the OSI (Open Systems Interconnection) architecture, although it is applicable to distributed, concurrent systems in general. In LOTOS a system is seen as a set of processes which interact and exchange data with each other and with their environment. LOTOS is expected to become an ISO international standard by 1988."
}

@article{fuzzchick,
author = {Lampropoulos, Leonidas and Hicks, Michael and Pierce, Benjamin C.},
title = {Coverage Guided, Property Based Testing},
year = {2019},
issue_date = {October 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {OOPSLA},
url = {https://doi.org/10.1145/3360607},
doi = {10.1145/3360607},
abstract = {Property-based random testing, exemplified by frameworks such as Haskell's QuickCheck, works by testing an executable predicate (a property) on a stream of randomly generated inputs. Property testing works very well in many cases, but not always. Some properties are conditioned on the input satisfying demanding semantic invariants that are not consequences of its syntactic structure---e.g., that an input list must be sorted or have no duplicates. Most randomly generated inputs fail to satisfy properties with such sparse preconditions, and so are simply discarded. As a result, much of the target system may go untested.  We address this issue with a novel technique called coverage guided, property based testing (CGPT). Our approach is inspired by the related area of coverage guided fuzzing, exemplified by tools like AFL. Rather than just generating a fresh random input at each iteration, CGPT can also produce new inputs by mutating previous ones using type-aware, generic mutator operators. The target program is instrumented to track which control flow branches are executed during a run and inputs whose runs expand control-flow coverage are retained for future mutations. This means that, when sparse conditions in the target are satisfied and new coverage is observed, the input that triggered them will be retained and used as a springboard to go further.  We have implemented CGPT as an extension to the QuickChick property testing tool for Coq programs; we call our implementation FuzzChick. We evaluate FuzzChick on two Coq developments for abstract machines that aim to enforce flavors of noninterference, which has a (very) sparse precondition. We systematically inject bugs in the machines' checking rules and use FuzzChick to look for counterexamples to the claim that they satisfy a standard noninterference property. We find that vanilla QuickChick almost always fails to find any bugs after a long period of time, as does an earlier proposal for combining property testing and fuzzing. In contrast, FuzzChick often finds them within seconds to minutes. Moreover, FuzzChick is almost fully automatic; although highly tuned, hand-written generators can find the bugs faster, they require substantial amounts of insight and manual effort.},
journal = {Proc. ACM Program. Lang.},
month = {oct},
articleno = {181},
numpages = {29},
keywords = {random testing, FuzzChick, AFL, fuzz testing, property-based testing, coverage, QuickChick}
}

@misc{afl,
  title={American fuzzy lop},
  author={Zalewski, Michal},
  year={2017}
}

@article{fuzz,
author = {Miller, Barton P. and Fredriksen, Louis and So, Bryan},
title = {An Empirical Study of the Reliability of UNIX Utilities},
year = {1990},
issue_date = {Dec. 1990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {12},
issn = {0001-0782},
url = {https://doi.org/10.1145/96267.96279},
doi = {10.1145/96267.96279},
abstract = {The following section describes the tools we built to test the utilities. These tools include the fuzz (random character) generator, ptyjig (to test interactive utilities), and scripts to automate the testing process. Next, we will describe the tests we performed, giving the types of input we presented to the utilities. Results from the tests will follow along with an analysis of the results, including identification and classification of the program bugs that caused the crashes. The final section presents concluding remarks, including suggestions for avoiding the types of problems detected by our study and some commentary on the bugs we found. We include an Appendix with the user manual pages for fuzz and ptyjig.},
journal = {Commun. ACM},
month = {dec},
pages = {32–44},
numpages = {13}
}

@software{honggfuzz,
  author={Swiecki, Robert},
  title={Honggfuzz},
  url={https://github.com/google/honggfuzz}
}

@article{narrowing,
author = {Antoy, Sergio and Echahed, Rachid and Hanus, Michael},
title = {A Needed Narrowing Strategy},
year = {2000},
issue_date = {July 2000},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {4},
issn = {0004-5411},
url = {https://doi.org/10.1145/347476.347484},
doi = {10.1145/347476.347484},
abstract = {The narrowing relation over terms constitutes the basis of the most important operational semantics of languages that integrate functional and logic programming paradigms. It also plays an important role in the definition of some algorithms of unification modulo equational theories that are defined by confluent term rewriting systems. Due to the inefficiency of simple narrowing, many refined narrowing strategies have been proposed in the last decade. This paper presents a new narrowing strategy that is optimal in several respects. For this purpose, we propose a notion of a needed narrowing step that, for inductively sequential rewrite systems, extends the Huet and L\'{e}vy notion of a needed reduction step. We define a strategy, based on this notion, that computes only needed  narrowing steps. Our strategy is sound and complete for a large class of rewrite systems, is optimal with respect to the cost measure that counts the number of distinct steps of a derivation, computes only incomparable and disjoint unifiers, and is efficiently implemented by unification.},
journal = {J. ACM},
month = {jul},
pages = {776–822},
numpages = {47},
keywords = {rewrite systems, narrowing strategies, call-by-need, functional logic programming languages}
}

@InProceedings{judge-cover,
author="Goldstein, Harrison
and Hughes, John
and Lampropoulos, Leonidas
and Pierce, Benjamin C.",
editor="Yoshida, Nobuko",
title="Do Judge a Test by its Cover",
booktitle="Programming Languages and Systems",
year="2021",
publisher="Springer International Publishing",
address="Cham",
pages="264--291",
abstract="Property-based testing uses randomly generated inputs to validate high-level program specifications. It can be shockingly effective at finding bugs, but it often requires generating a very large number of inputs to do so. In this paper, we apply ideas from combinatorial testing, a powerful and widely studied testing methodology, to modify the distributions of our random generators so as to find bugs with fewer tests. The key concept is combinatorial coverage, which measures the degree to which a given set of tests exercises every possible choice of values for every small combination of input features.",
isbn="978-3-030-72019-3"
}

@url{vailshery,
title={Quality assurance and testing budget allocation 2012--2019},
url={https://www.statista.com/statistics/500641/worldwide-qa-budget-allocation-as-percent-it-spend/},
journal={Statista},
author={Vailshery, Lionel Sujay},
year={2022},
month={Feb}
}

@software{SimpleIO,
author = {Xia, Li-yao and Li, Yishuai},
license = {MIT},
title = {{Coq SimpleIO}},
url = {https://github.com/Lysxia/coq-simple-io}
}